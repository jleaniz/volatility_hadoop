{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Storage Commands\n",
    "\n",
    "Cloud Datalab provides a set of commands for working with data stored in Google Cloud Storage. This is especially interesting for working against data files containing data that is not in BigQuery, or to use it for managing data imported into or exported from BigQuery.\n",
    "\n",
    "This notebook introduces various Storage commands that Cloud Datalab introduces into the notebook environment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Commands\n",
    "\n",
    "The commands cover the ability to list storage buckets, and the contained objects, manage them, as well as read from and write to those objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: storage [-h] {copy,create,delete,list,read,view,write} ...\n",
      "\n",
      "Execute various storage-related operations. Use \"%storage <command> -h\" for\n",
      "help on a specific command.\n",
      "\n",
      "positional arguments:\n",
      "  {copy,create,delete,list,read,view,write}\n",
      "                        commands\n",
      "    copy                Copy one or more GCS objects to a different location.\n",
      "    create              Create one or more GCS buckets.\n",
      "    delete              Delete one or more GCS buckets or objects.\n",
      "    list                List buckets in a project, or contents of a bucket.\n",
      "    read                Read the contents of a storage object into a Python\n",
      "                        variable.\n",
      "    view                View the contents of a storage object.\n",
      "    write               Write the value of a Python variable to a storage\n",
      "                        object.\n",
      "\n",
      "optional arguments:\n",
      "  -h, --help            show this help message and exit\n"
     ]
    }
   ],
   "source": [
    "%%storage --help"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Buckets and Objects\n",
    "\n",
    "Items or files held in Cloud Storage are called objects. These are immutable once written. They are organized into buckets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Listing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try this command to list any buckets within the current project:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%storage list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Some code to determine a unique bucket name for the purposes of the sample\n",
    "import gcp\n",
    "\n",
    "project = gcp.Context.default().project_id\n",
    "sample_bucket_name = project + '-datalab-samples'\n",
    "sample_bucket_path = 'gs://' + sample_bucket_name\n",
    "sample_bucket_object = sample_bucket_path + '/hello.txt'\n",
    "\n",
    "print 'Bucket: ' + sample_bucket_path\n",
    "print 'Object: ' + sample_bucket_object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE: In the examples below, the variables will be referenced in the command using `$` syntax, since the names are determined based on the current project. In your scenarios, you might be able to use literal values if they are constant, rather than creating and using variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%storage create -b $sample_bucket_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%storage list -b $sample_bucket_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%storage list -b gs://cloud-datalab-samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%storage copy -s gs://cloud-datalab-samples/hello.txt -d $sample_bucket_object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%storage list -b $sample_bucket_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading and Writing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%storage view -o $sample_bucket_object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%storage read -o $sample_bucket_object -v text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text = 'Hello World!\\n====\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%storage write -v text -o $sample_bucket_object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%storage list -b $sample_bucket_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Looking Ahead\n",
    "\n",
    "The Storage commands seen above build on the Storage APIs included in Cloud Datalab. The next notebook will demonstrate these APIs.\n",
    "\n",
    "Additionally, the BigQuery functionality supports exporting data to and importing data from Cloud Storage, as shown in the BigQuery tutorials."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
